{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T00:39:20.054895100Z",
     "start_time": "2024-02-07T00:39:18.958157900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load modules and set configurations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, copy, random, pickle, gc\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8a139b",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed1bb534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel as pdrl\n",
    "pdrl.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7000b2b7",
   "metadata": {},
   "source": [
    "## 1.1 splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c98e6d68224b869c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T00:39:52.644248800Z",
     "start_time": "2024-02-07T00:39:23.874641400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data loading\n",
    "resampling_hour = '2h'\n",
    "with open(f'stay_ids-{resampling_hour}.pkl', 'rb') as f:\n",
    "    stay_ids = pickle.load(f)\n",
    "\n",
    "drop_cols = [f'label_after_{i}hour' for i in range(1, 7)]\n",
    "df = pd.read_feather(f'ED_new_{resampling_hour}our_forward_full.ftr').drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e392399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional column defining\n",
    "df['true'] = np.where(df['stay_id'].isin(stay_ids['a']), 1, 0)\n",
    "df['n_seq'] = np.concatenate(np.repeat([np.arange(24)], repeats=stay_ids['all'].__len__(), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37506932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nzp = df[df['time']!='0'].reset_index(drop=True) # delete zero paddings\n",
    "# esi setting 1: 1,2/ 3,4,5\n",
    "# esi setting 2: 1/ 2,3,4,5\n",
    "# esi setting 3: 1,2,3/ 4,5\n",
    "for idx, i in enumerate([[1, 2], [1], [1, 2, 3]]):\n",
    "    df_nzp[f'low_esi{idx+1}'] = np.where(df_nzp['stay_id'].isin(df_nzp[~df_nzp['acuity'].isin(i)]['stay_id'].unique()), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16773953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make splits for each esi settings \n",
    "for ver in [1, 2, 3]:\n",
    "    for low_esi in [0, 1]:\n",
    "        tmp_df = df_nzp.query(f'low_esi{ver}=={low_esi}').reset_index(drop=True)\n",
    "        \n",
    "        split_ids = {}\n",
    "        a_ids = tmp_df.query('true==1')['stay_id'].unique()\n",
    "        n_ids = tmp_df.query('true==0')['stay_id'].unique()\n",
    "        a_len = a_ids.__len__()\n",
    "        n_len = n_ids.__len__()\n",
    "\n",
    "        seed_everything(SEED)\n",
    "        rng = np.random.RandomState(SEED)\n",
    "\n",
    "        tst_len = a_len//2\n",
    "        val_th_len = a_len - a_len//2\n",
    "        trn_len = round((n_len - a_len)/10*9)\n",
    "        val_tr_len = n_len - a_len - trn_len\n",
    "\n",
    "        split_ids['trn'] = rng.choice(n_ids, trn_len, replace=False)\n",
    "        n_ids = np.setdiff1d(n_ids, split_ids['trn'])\n",
    "\n",
    "        split_ids['val_tr'] = np.random.choice(n_ids, val_tr_len, replace=False)\n",
    "        n_ids = np.setdiff1d(n_ids, split_ids['val_tr'])\n",
    "\n",
    "        split_ids['val_th'] = np.concatenate([rng.choice(n_ids, val_th_len, replace=False), rng.choice(a_ids, val_th_len, replace=False)])\n",
    "        a_ids = np.setdiff1d(a_ids, split_ids['val_th'])\n",
    "        n_ids = np.setdiff1d(n_ids, split_ids['val_th'])\n",
    "\n",
    "        split_ids['tst'] = np.concatenate([n_ids, a_ids])\n",
    "        \n",
    "        for i, j in split_ids.items():\n",
    "            cond = df_nzp['stay_id'].isin(j)\n",
    "            df_nzp.loc[cond, f'split_esi{ver}_{low_esi}'] = i\n",
    "\n",
    "        cond = df_nzp[f'split_esi{ver}_{low_esi}'] == 'val_th'\n",
    "        tmp_df = df_nzp[cond].reset_index(drop=True)\n",
    "        a_ids = tmp_df.query('true==1')['stay_id'].unique().tolist()\n",
    "        n_ids = tmp_df.query('true==0')['stay_id'].unique().tolist()\n",
    "        a_len = len(a_ids); q = a_len//2; r = a_len%2\n",
    "\n",
    "        split_ids = {\n",
    "            'trn': np.concatenate([df_nzp[df_nzp[f'split_esi{ver}_{low_esi}']=='trn']['stay_id'].unique(), a_ids[:q+r]+n_ids[:q+r]]),\n",
    "            'val': a_ids[q+r:]+n_ids[q+r:],\n",
    "            'tst': df_nzp[df_nzp[f'split_esi{ver}_{low_esi}']=='tst']['stay_id'].unique()\n",
    "        }\n",
    "\n",
    "        for i, j in split_ids.items():\n",
    "            cond = df_nzp['stay_id'].isin(j)\n",
    "            df_nzp.loc[cond, f'split_esi{ver}_{low_esi}_ml'] = i\n",
    "\n",
    "    split_ids = {s: np.concatenate([df_nzp[df_nzp[f'split_esi{ver}_{low_esi}_ml']==s]['stay_id'].unique() for low_esi in [0, 1]]) for s in ['trn', 'val', 'tst']} \n",
    "\n",
    "    for i, j in split_ids.items():\n",
    "        cond = df_nzp['stay_id'].isin(j)\n",
    "        df_nzp.loc[cond, f'split_esi{ver}_ml'] = i\n",
    "\n",
    "    split_ids = {s: np.concatenate([df_nzp[df_nzp[f'split_esi{ver}_{low_esi}']==s]['stay_id'].unique() for low_esi in [0, 1]]) for s in ['trn', 'val_tr', 'val_th', 'tst']} \n",
    "    \n",
    "    for i, j in split_ids.items():\n",
    "        cond = df_nzp['stay_id'].isin(j)\n",
    "        df_nzp.loc[cond, f'split_esi{ver}'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b9671ac5473760c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T09:11:29.360019200Z",
     "start_time": "2024-02-07T09:11:29.275332700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_esi1_0\n",
      "trn       79482\n",
      "tst        9136\n",
      "val_th     9136\n",
      "val_tr     8831\n",
      "Name: stay_id, dtype: int64\n",
      "split_esi1_0_ml\n",
      "trn    84050\n",
      "tst     9136\n",
      "val     4568\n",
      "Name: stay_id, dtype: int64\n",
      "True\n",
      "================================================================================================================================================\n",
      "split_esi1_1\n",
      "trn       169855\n",
      "tst         1246\n",
      "val_th      1248\n",
      "val_tr     18873\n",
      "Name: stay_id, dtype: int64\n",
      "split_esi1_1_ml\n",
      "trn    170479\n",
      "tst      1246\n",
      "val       624\n",
      "Name: stay_id, dtype: int64\n",
      "True\n",
      "================================================================================================================================================\n",
      "split_esi2_0\n",
      "trn       6853\n",
      "tst       2998\n",
      "val_th    2998\n",
      "val_tr     761\n",
      "Name: stay_id, dtype: int64\n",
      "split_esi2_0_ml\n",
      "trn    8353\n",
      "tst    2998\n",
      "val    1498\n",
      "Name: stay_id, dtype: int64\n",
      "True\n",
      "================================================================================================================================================\n",
      "split_esi2_1\n",
      "trn       242484\n",
      "tst         7384\n",
      "val_th      7386\n",
      "val_tr     26943\n",
      "Name: stay_id, dtype: int64\n",
      "split_esi2_1_ml\n",
      "trn    246178\n",
      "tst      7384\n",
      "val      3692\n",
      "Name: stay_id, dtype: int64\n",
      "True\n",
      "================================================================================================================================================\n",
      "split_esi3_0\n",
      "trn       228495\n",
      "tst        10354\n",
      "val_th     10356\n",
      "val_tr     25388\n",
      "Name: stay_id, dtype: int64\n",
      "split_esi3_0_ml\n",
      "trn    233673\n",
      "tst     10354\n",
      "val      5178\n",
      "Name: stay_id, dtype: int64\n",
      "True\n",
      "================================================================================================================================================\n",
      "split_esi3_1\n",
      "trn       20842\n",
      "tst          28\n",
      "val_th       28\n",
      "val_tr     2316\n",
      "Name: stay_id, dtype: int64\n",
      "split_esi3_1_ml\n",
      "trn    20856\n",
      "tst       28\n",
      "val       14\n",
      "Name: stay_id, dtype: int64\n",
      "True\n",
      "================================================================================================================================================\n",
      "split_esi1_ml\n",
      "trn    254529\n",
      "tst     10382\n",
      "val      5192\n",
      "Name: stay_id, dtype: int64\n",
      "True\n",
      "================================================================================================================================================\n",
      "split_esi2_ml\n",
      "trn    254531\n",
      "tst     10382\n",
      "val      5190\n",
      "Name: stay_id, dtype: int64\n",
      "True\n",
      "================================================================================================================================================\n",
      "split_esi3_ml\n",
      "trn    254529\n",
      "tst     10382\n",
      "val      5192\n",
      "Name: stay_id, dtype: int64\n",
      "True\n",
      "================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# sanity check for split\n",
    "for ver, low_esi in product([1, 2, 3], [0, 1]):\n",
    "    print(df_nzp.groupby(f'split_esi{ver}_{low_esi}')['stay_id'].nunique())\n",
    "    print(df_nzp.groupby(f'split_esi{ver}_{low_esi}_ml')['stay_id'].nunique())\n",
    "    print(all(np.sort(df_nzp[df_nzp[f'low_esi{ver}']==low_esi]['stay_id'].unique()) == np.sort(df_nzp[~df_nzp[f'split_esi{ver}_{low_esi}'].isna()]['stay_id'].unique())))\n",
    "    print('================================================================================================================================================')\n",
    "\n",
    "for ver in [1, 2, 3]:\n",
    "    print(df_nzp.groupby(f'split_esi{ver}_ml')['stay_id'].nunique())\n",
    "    print(all(np.sort(df_nzp[df_nzp[f'split_esi{ver}']!='val_tr']['stay_id'].unique()) == np.sort(df_nzp[~df_nzp[f'split_esi{ver}_ml'].isna()]['stay_id'].unique())))\n",
    "    print('================================================================================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3650635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [i for i in df_nzp.columns if i.__contains__('_esi')]\n",
    "df = pd.merge(df, df_nzp[['stay_id']+cols].drop_duplicates(), how='outer', on='stay_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a840b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather('data-df-split.ftr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0078183e",
   "metadata": {},
   "source": [
    "## 1.2 scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73731a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('data-df-split.ftr')\n",
    "\n",
    "# columns defining \n",
    "tmp = ['stay_id', 'time', 'true', 'n_seq']+[j for j in df.columns if j.__contains__('_esi')]\n",
    "scaling_cols = [col for col in df.columns if df[col].nunique() > 2]\n",
    "scaling_cols = [i for i in scaling_cols if i not in tmp]\n",
    "features = [i for i in df.columns if i not in tmp]\n",
    "\n",
    "# data type conversion\n",
    "df[features] = df[features].astype(np.float32)\n",
    "df[['stay_id', 'true']] = df[['stay_id', 'true']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b80da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ver in tqdm([1, 2, 3]):\n",
    "    for low_esi in [0, 1]:\n",
    "        tmp_df = df.query(f'low_esi{ver}=={low_esi}').reset_index(drop=True)\n",
    "        zp_cond = tmp_df['time']!='0'\n",
    "        \n",
    "        for ml in ['', '_ml']:\n",
    "            if ml == '_ml':\n",
    "                splits = ['trn', 'val', 'tst']\n",
    "            else:\n",
    "                splits = ['trn', 'val_tr', 'val_th', 'tst']\n",
    "\n",
    "            tmp = tmp_df.copy()\n",
    "            split_col = f'split_esi{ver}_{low_esi}{ml}'\n",
    "            mus = tmp.query(f'{split_col}==\"trn\"').loc[zp_cond, scaling_cols].mean(axis=0)\n",
    "            stds = tmp.query(f'{split_col}==\"trn\"').loc[zp_cond, scaling_cols].std(axis=0)\n",
    "            for i in splits:\n",
    "                cond = (tmp[split_col]==i) & zp_cond\n",
    "                tmp.loc[cond, scaling_cols] = (tmp.loc[cond, scaling_cols]-mus)/(stds+1e-09)\n",
    "            \n",
    "            if ml == '_ml':\n",
    "                tmp[zp_cond].reset_index(drop=True).to_feather(f'data-df-std-esi{ver}-{low_esi}{ml}.ftr')\n",
    "            else:\n",
    "                tmp.to_feather(f'data-df-std-esi{ver}-{low_esi}{ml}.ftr')\n",
    "\n",
    "    for ml in ['', '_ml']:\n",
    "        if ml == '_ml':\n",
    "            splits = ['trn', 'val', 'tst']\n",
    "        else:\n",
    "            splits = ['trn', 'val_tr', 'val_th', 'tst']\n",
    "\n",
    "        tmp = df.copy()\n",
    "        zp_cond = tmp['time']!='0'\n",
    "        split_col = f'split_esi{ver}{ml}'\n",
    "        mus = tmp.query(f'{split_col}==\"trn\"').loc[zp_cond, scaling_cols].mean(axis=0)\n",
    "        stds = tmp.query(f'{split_col}==\"trn\"').loc[zp_cond, scaling_cols].std(axis=0)\n",
    "        for i in splits:\n",
    "            cond = (tmp[split_col]==i) & zp_cond\n",
    "            tmp.loc[cond, scaling_cols] = (tmp.loc[cond, scaling_cols]-mus)/(stds+1e-09)\n",
    "\n",
    "        if ml == '_ml':\n",
    "            tmp[zp_cond].reset_index(drop=True).to_feather(f'data-df-std-esi{ver}{ml}.ftr')\n",
    "        else:\n",
    "            tmp.reset_index(drop=True).to_feather(f'data-df-std-esi{ver}{ml}.ftr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f472d009",
   "metadata": {},
   "source": [
    "## 1.3 preparing for lstm ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17441fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(f'data-df-split.ftr')\n",
    "max_seq_len = 24\n",
    "\n",
    "tmp = ['stay_id', 'time', 'true', 'n_seq']+[j for j in df.columns if j.__contains__('_esi')]\n",
    "features = [i for i in df.columns if i not in tmp]\n",
    "n_zp_cols = ['stay_id']+[j for j in df.columns if j.__contains__('_esi')]\n",
    "zp_cols = [i for i in df.columns if i not in n_zp_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d74a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamps_split_zero_padding(df, max_seq_len=max_seq_len):\n",
    "    n_col = len(df.columns)\n",
    "    tmp = df.values.reshape(-1, max_seq_len, n_col)\n",
    "    mask_padded = tmp[:, :, 1] == '0'\n",
    "    len_seqs = 24-np.sum(mask_padded, axis=1)\n",
    "    seqs = []\n",
    "    \n",
    "    for idx, ls in tqdm(enumerate(len_seqs)):\n",
    "        if ls == 1:\n",
    "            _seq = tmp[idx].copy()\n",
    "            seqs.append(_seq.copy())\n",
    "            continue\n",
    "        \n",
    "        stayid = tmp[idx, 0, 0]\n",
    "        result = tmp[idx, 0, -1]\n",
    "        \n",
    "        for i in range(1, ls):\n",
    "            _seq = tmp[idx].copy()\n",
    "            _seq[i:, :] = [[stayid, '0']+np.repeat(0, n_col-3).tolist()+[result] for _ in range(max_seq_len-i)]\n",
    "            seqs.append(_seq.copy())\n",
    "        \n",
    "        _seq = tmp[idx].copy()\n",
    "        seqs.append(_seq.copy())\n",
    "\n",
    "    seqs = np.array(seqs)\n",
    "    seqs = seqs.reshape(-1, n_col)\n",
    "\n",
    "    return pd.DataFrame(seqs, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d8754a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9136it [00:06, 1371.58it/s]\n",
      "9136it [00:06, 1396.45it/s]\n",
      "1248it [00:01, 1169.13it/s]\n",
      "1246it [00:00, 1282.33it/s]\n",
      "10384it [00:07, 1388.64it/s]\n",
      "10382it [00:07, 1370.41it/s]\n",
      "2998it [00:01, 1581.59it/s]\n",
      "2998it [00:01, 1619.13it/s]\n",
      "7386it [00:05, 1368.75it/s]\n",
      "7384it [00:05, 1412.93it/s]\n",
      "10384it [00:07, 1408.52it/s]\n",
      "10382it [00:07, 1454.15it/s]\n",
      "10356it [00:07, 1359.05it/s]\n",
      "10354it [00:07, 1408.52it/s]\n",
      "28it [00:00, 2005.23it/s]\n",
      "28it [00:00, 2370.57it/s]\n",
      "10384it [00:07, 1372.86it/s]\n",
      "10382it [00:07, 1414.35it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dict = {ver:{low_esi:{} for low_esi in [0, 1, 'all']} for ver in [1, 2, 3]}\n",
    "for ver in [1, 2, 3]:\n",
    "    for low_esi in [0, 1]:\n",
    "        df = pd.read_feather(f'data-df-std-esi{ver}-{low_esi}.ftr')\n",
    "        split_col = f'split_esi{ver}_{low_esi}'    \n",
    "        data = {i: df.query(f'{split_col}==@i').reset_index(drop=True) for i in ['trn', 'val_tr', 'val_th', 'tst']}\n",
    "\n",
    "        for i in ['val_th', 'tst']:\n",
    "            data[i] = timestamps_split_zero_padding(data[i])\n",
    "\n",
    "        data_dict[ver][low_esi] = copy.deepcopy(data)\n",
    "\n",
    "\n",
    "    df = pd.read_feather(f'data-df-std-esi{ver}.ftr')\n",
    "    split_col = f'split_esi{ver}'    \n",
    "    data = {i: df.query(f'{split_col}==@i').reset_index(drop=True) for i in ['trn', 'val_tr', 'val_th', 'tst']}\n",
    "    for i in ['val_th', 'tst']:\n",
    "        data[i] = timestamps_split_zero_padding(data[i])\n",
    "    \n",
    "    data_dict[ver]['all'] = copy.deepcopy(data)\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a77f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:11<00:00, 17.98s/it]\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.05s/it]\n",
      "100%|██████████| 4/4 [01:23<00:00, 20.87s/it]\n",
      "100%|██████████| 4/4 [00:21<00:00,  5.35s/it]\n",
      "100%|██████████| 4/4 [00:58<00:00, 14.72s/it]\n",
      "100%|██████████| 4/4 [01:19<00:00, 20.00s/it]\n",
      "100%|██████████| 4/4 [01:20<00:00, 20.22s/it]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.74it/s]\n",
      "100%|██████████| 4/4 [01:20<00:00, 20.18s/it]\n"
     ]
    }
   ],
   "source": [
    "for ver in [1, 2, 3]:\n",
    "    for low_esi in [0, 1, 'all']:\n",
    "        for i in tqdm(['trn', 'val_tr', 'val_th', 'tst']):\n",
    "            tmp = {\n",
    "                'X': data_dict[ver][low_esi][i][features].values.reshape((-1, max_seq_len, len(features))),\n",
    "                'y': data_dict[ver][low_esi][i]['true'].values.reshape((-1, max_seq_len, 1)),\n",
    "                'ids': data_dict[ver][low_esi][i]['stay_id'].values.reshape((-1, max_seq_len, 1)),\n",
    "                'n_seq': data_dict[ver][low_esi][i]['n_seq'].values.reshape((-1, max_seq_len, 1))\n",
    "            }\n",
    "\n",
    "            data_dict[ver][low_esi][i] = copy.deepcopy(tmp)\n",
    "\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c30527d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data-dict-for_lstm_ae.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeea43e",
   "metadata": {},
   "source": [
    "## 1.4 preparing for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff91c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(f'data-df-split.ftr')\n",
    "\n",
    "tmp = ['stay_id', 'time', 'true', 'n_seq']+[j for j in df.columns if j.__contains__('_esi')]\n",
    "features = [i for i in df.columns if i not in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "511e7f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {ver:{low_esi:{} for low_esi in [0, 1, 'all']} for ver in [1, 2, 3]}\n",
    "for ver in [1, 2, 3]:\n",
    "    for low_esi in [0, 1]:\n",
    "        df = pd.read_feather(f'data-df-std-esi{ver}-{low_esi}_ml.ftr')\n",
    "        df = df[df['time']!='0'].reset_index(drop=True)\n",
    "        \n",
    "        split_col = f'split_esi{ver}_{low_esi}_ml'    \n",
    "        data = {i: df.query(f'{split_col}==@i').reset_index(drop=True) for i in ['trn', 'val', 'tst']}\n",
    "\n",
    "        data_dict[ver][low_esi] = copy.deepcopy(data)\n",
    "\n",
    "    df = pd.read_feather(f'data-df-std-esi{ver}_ml.ftr')\n",
    "    df = df[df['time']!='0'].reset_index(drop=True)\n",
    "    split_col = f'split_esi{ver}_ml'    \n",
    "    data = {i: df.query(f'{split_col}==@i').reset_index(drop=True) for i in ['trn', 'val', 'tst']}\n",
    "    \n",
    "    data_dict[ver]['all'] = copy.deepcopy(data)\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6964cf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 24.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 12.79it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.50it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 167.54it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  6.63it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.66it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 150.78it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.81it/s]\n"
     ]
    }
   ],
   "source": [
    "for ver in [1, 2, 3]:\n",
    "    for low_esi in [0, 1, 'all']:\n",
    "        for i in tqdm(['trn', 'val', 'tst']):\n",
    "            tmp = {\n",
    "                'X': data_dict[ver][low_esi][i][features].values,\n",
    "                'y': data_dict[ver][low_esi][i]['true'].values.ravel(),\n",
    "                'ids': data_dict[ver][low_esi][i]['stay_id'].values.ravel(),\n",
    "                'n_seq': data_dict[ver][low_esi][i]['n_seq'].values.ravel()\n",
    "            }\n",
    "\n",
    "            data_dict[ver][low_esi][i] = copy.deepcopy(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a77177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data-dict-for_ml.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf171dff",
   "metadata": {},
   "source": [
    "## 1.5 preparing for AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b7d0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(f'data-df-split.ftr')\n",
    "\n",
    "tmp = ['stay_id', 'time', 'true', 'n_seq']+[j for j in df.columns if j.__contains__('_esi')]\n",
    "features = [i for i in df.columns if i not in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff577f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {ver:{low_esi:{} for low_esi in [0, 1, 'all']} for ver in [1, 2, 3]}\n",
    "for ver in [1, 2, 3]:\n",
    "    for low_esi in [0, 1]:\n",
    "        df = pd.read_feather(f'data-df-std-esi{ver}-{low_esi}.ftr')\n",
    "        df = df[df['time']!='0'].reset_index(drop=True)\n",
    "        \n",
    "        split_col = f'split_esi{ver}_{low_esi}'    \n",
    "        data = {i: df.query(f'{split_col}==@i').reset_index(drop=True) for i in ['trn', 'val_tr', 'val_th', 'tst']}\n",
    "\n",
    "        data_dict[ver][low_esi] = copy.deepcopy(data)\n",
    "\n",
    "    df = pd.read_feather(f'data-df-std-esi{ver}.ftr')\n",
    "    df = df[df['time']!='0'].reset_index(drop=True)\n",
    "    split_col = f'split_esi{ver}'\n",
    "    data = {i: df.query(f'{split_col}==@i').reset_index(drop=True) for i in ['trn', 'val_tr', 'val_th', 'tst']}\n",
    "    \n",
    "    data_dict[ver]['all'] = copy.deepcopy(data)\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f29cb76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 25.27it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 16.64it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  8.92it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 199.71it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.56it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  7.32it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.73it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 234.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.44it/s]\n"
     ]
    }
   ],
   "source": [
    "for ver in [1, 2, 3]:\n",
    "    for low_esi in [0, 1, 'all']:\n",
    "        for i in tqdm(['trn', 'val_tr', 'val_th', 'tst']):\n",
    "            tmp = {\n",
    "                'X': data_dict[ver][low_esi][i][features].values,\n",
    "                'y': data_dict[ver][low_esi][i]['true'].values,\n",
    "                'ids': data_dict[ver][low_esi][i]['stay_id'].values,\n",
    "                'n_seq': data_dict[ver][low_esi][i]['n_seq'].values\n",
    "            }\n",
    "\n",
    "            data_dict[ver][low_esi][i] = copy.deepcopy(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86aee800",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data-dict-for_ae.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b72d6",
   "metadata": {},
   "source": [
    "## 1.6 preparing for PCA LSTM AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175072ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data-dict-for_lstm_ae.pkl', 'rb') as f:\n",
    "    data_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c31001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "pca = PCA(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d2cba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.05s/it]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.01it/s]\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.35s/it]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.41it/s]\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.08s/it]\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.33s/it]\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.32s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 52.19it/s]\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "for ver in [1, 2, 3]:\n",
    "    for low_esi in [0, 1, 'all']:\n",
    "        tmp_X = data_dict[ver][low_esi]['trn']['X'].reshape(-1, 114)\n",
    "        zp_mask = np.all(tmp_X == 0, axis=1)\n",
    "        pca.fit(tmp_X[~zp_mask])\n",
    "\n",
    "        for i in tqdm(['trn', 'val_tr', 'val_th', 'tst']):\n",
    "            tmp_X = data_dict[ver][low_esi][i]['X'].reshape(-1, 114)\n",
    "            zp_mask = np.all(tmp_X == 0, axis=1)\n",
    "            pca_X = np.zeros((tmp_X.shape[0], 1))\n",
    "\n",
    "            pca_X[~zp_mask] = pca.transform(tmp_X[~zp_mask])\n",
    "\n",
    "            data_dict[ver][low_esi][i]['X'] = copy.deepcopy(pca_X.reshape(-1, 24, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac2c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data-dict-for_pca_lstm_ae.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
