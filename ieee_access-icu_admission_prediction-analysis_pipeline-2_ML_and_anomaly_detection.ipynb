{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T00:39:20.054895100Z",
     "start_time": "2024-02-07T00:39:18.958157900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load modules and set configurations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, copy, random, pickle, gc\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f8b45",
   "metadata": {},
   "source": [
    "# 2. ML and anmoaly detection algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78bceb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from functools import partial\n",
    "\n",
    "with open(f'data-dict-for_ml.pkl', 'rb') as f:\n",
    "    data_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4179fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ver = 1 # 1, 2, 3\n",
    "low_esi = 1 # 0, 1, 'all'\n",
    "\n",
    "data = data_dict[ver][low_esi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34496068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "mdl = 'xgb' # xgb cat lgb ran lr lof, mahalanobis iso\n",
    "contamination = data['trn']['y'].sum()/len(data['trn']['y'])\n",
    "if mdl == 'lof':\n",
    "    model = LocalOutlierFactor(n_neighbors=3, contamination=contamination, novelty=True)\n",
    "elif mdl == 'mahalanobis':\n",
    "    model = EllipticEnvelope(contamination=contamination, random_state=SEED)\n",
    "elif mdl == 'iso':\n",
    "    model = IsolationForest(contamination=contamination, random_state=SEED)\n",
    "\n",
    "elif mdl == 'xgb':\n",
    "    model = XGBClassifier(random_state=SEED)\n",
    "elif mdl == 'cat':\n",
    "    model = CatBoostClassifier(random_state=SEED, verbose=False)\n",
    "elif mdl == 'lgb':\n",
    "    model = LGBMClassifier(random_state=SEED)\n",
    "elif mdl == 'ran':\n",
    "    model = RandomForestClassifier(random_state=SEED)\n",
    "elif mdl == 'lr':\n",
    "    model = LogisticRegression(random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "740f6969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "if mdl in ['mahalanobis', 'iso', 'lof']:\n",
    "    model.fit(data['trn']['X'])\n",
    "else: \n",
    "    model.fit(data['trn']['X'], data['trn']['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d89753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation data\n",
    "eval_split = 'val'#tst val\n",
    "if mdl == 'mahalanobis':\n",
    "    score = model.mahalanobis(data[eval_split]['X'])\n",
    "\n",
    "elif mdl in ['iso', 'lof']:\n",
    "    score = -model.score_samples(data[eval_split]['X'])\n",
    "\n",
    "else:\n",
    "    score = model.predict_proba(data[eval_split]['X'])[:, 1]\n",
    "\n",
    "eval_data = pd.DataFrame()\n",
    "eval_data['id'] = data[eval_split]['ids']\n",
    "eval_data['true'] = data[eval_split]['y']\n",
    "eval_data['score'] = score\n",
    "eval_data['n_seq'] = data[eval_split]['n_seq']\n",
    "\n",
    "eval_data.to_csv(f\"eval_data-low_esi{ver}-{low_esi}-{mdl}-{eval_split}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff144e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2652/2652 [00:29<00:00, 90.81it/s]\n"
     ]
    }
   ],
   "source": [
    "def conf_mat(true, pred):\n",
    "    tp = ((pred == 1) & (true == 1)).sum()\n",
    "    fp = ((pred == 1) & (true == 0)).sum()\n",
    "    fn = ((pred == 0) & (true == 1)).sum()\n",
    "    tn = ((pred == 0) & (true == 0)).sum()\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "eval_split = 'val' # val tst\n",
    "for mdl in ['xgb', 'cat', 'lgb', 'ran', 'lr', 'mahalanobis', 'lof', 'iso']: \n",
    "    eval_result = []\n",
    "    eval_data = pd.read_csv(f'eval_data-low_esi{ver}-{low_esi}-{mdl}-{eval_split}.csv')\n",
    "    scores = eval_data['score'].unique()\n",
    "\n",
    "    for s in tqdm(scores):\n",
    "        eval_data['pred'] = np.where(eval_data['score']>=s, 1, 0)\n",
    "        tmp = eval_data.groupby('id').agg({'true': lambda x: x.values[0], 'pred': 'max'}).reset_index()\n",
    "        tp, fp, fn, tn = conf_mat(tmp['true'], tmp['pred'])\n",
    "\n",
    "        eval_result.append([s, tp/(tp+fn), tp/(tp+fp), 2*tp/(fp+2*tp+fn)])\n",
    "\n",
    "    eval_result = pd.DataFrame(eval_result, columns=['score', 'rec', 'prec', 'f1'])\n",
    "    eval_result.to_csv(f'eval_result-low_esi{ver}-{low_esi}-{mdl}-{eval_split}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af8d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat(true, pred):\n",
    "    tp = ((pred == 1) & (true == 1)).sum()\n",
    "    fp = ((pred == 1) & (true == 0)).sum()\n",
    "    fn = ((pred == 0) & (true == 1)).sum()\n",
    "    tn = ((pred == 0) & (true == 0)).sum()\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "eval_split = 'tst' # val tst\n",
    "for mdl in ['xgb', 'cat', 'lgb', 'ran', 'lr', 'mahalanobis', 'lof', 'iso']: \n",
    "    eval_result = []\n",
    "    eval_data = pd.read_csv(f'eval_data-low_esi{ver}-{low_esi}-{mdl}-{eval_split}.csv')\n",
    "    scores = eval_data['score'].unique()\n",
    "\n",
    "    for s in tqdm(scores):\n",
    "        eval_data['pred'] = np.where(eval_data['score']>=s, 1, 0)\n",
    "        tmp = eval_data.groupby('id').agg({'true': lambda x: x.values[0], 'pred': 'max'}).reset_index()\n",
    "        tp, fp, fn, tn = conf_mat(tmp['true'], tmp['pred'])\n",
    "\n",
    "        eval_result.append([s, tp/(tp+fn), tp/(tp+fp), 2*tp/(fp+2*tp+fn)])\n",
    "\n",
    "    eval_result = pd.DataFrame(eval_result, columns=['score', 'rec', 'prec', 'f1'])\n",
    "    eval_result.to_csv(f'eval_result-low_esi{ver}-{low_esi}-{mdl}-{eval_split}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016bf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb recall@prec0.7: 0.8301282051282052\n"
     ]
    }
   ],
   "source": [
    "prec_cf = 0.7\n",
    "for mdl in ['xgb', 'cat', 'lgb', 'ran', 'lr', 'mahalanobis', 'lof', 'iso']: #['xgb', 'cat', 'lgb', 'ran', 'lr', 'mahalanobis', 'lof', 'iso']\n",
    "    eval_result = pd.read_csv(f'eval_result-low_esi{ver}-{low_esi}-{mdl}-{eval_split}.csv')\n",
    "    print(f\"{mdl} recall@prec{prec_cf}: {eval_result.query('prec>=@prec_cf')['rec'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6bd985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d61265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2833b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d0bd23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68755809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat(true, pred):\n",
    "    tp = ((pred == 1) & (true == 1)).sum()\n",
    "    fp = ((pred == 1) & (true == 0)).sum()\n",
    "    fn = ((pred == 0) & (true == 1)).sum()\n",
    "    tn = ((pred == 0) & (true == 0)).sum()\n",
    "    return tp, fp, fn, tn\n",
    "eval_split = 'tst' # val tst\n",
    "ver = 1\n",
    "low_esi = 1\n",
    "for mdl in ['lstm_ae_layer']:\n",
    "    eval_result = []\n",
    "    eval_data = pd.read_csv(f'eval_data-low_esi{ver}-{low_esi}-{mdl}-{eval_split}.csv')\n",
    "    scores = eval_data['loss'].unique()\n",
    "    for s in tqdm(scores):\n",
    "        eval_data['pred'] = np.where(eval_data['loss']>=s, 1, 0)\n",
    "        tmp = eval_data.groupby('id').agg({'true': lambda x: x.values[0], 'pred': 'max'}).reset_index()\n",
    "        tp, fp, fn, tn = conf_mat(tmp['true'], tmp['pred'])\n",
    "        eval_result.append([s, tp/(tp+fn), tp/(tp+fp), 2*tp/(fp+2*tp+fn)])\n",
    "    eval_result = pd.DataFrame(eval_result, columns=['score', 'rec', 'prec', 'f1'])\n",
    "    eval_result.to_csv(f'eval_result-low_esi{ver}-{low_esi}-{mdl}-{eval_split}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026566a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_torch_py39",
   "language": "python",
   "name": "torch_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
