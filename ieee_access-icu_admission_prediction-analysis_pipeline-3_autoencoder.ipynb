{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T00:39:20.054895100Z",
     "start_time": "2024-02-07T00:39:18.958157900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load modules and set configurations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, copy, random, pickle, gc\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce2af8c",
   "metadata": {},
   "source": [
    "# 3. Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f36d7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F \n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            torch.nn.Linear(32, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, input_size),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "with open(f'data-dict-for_ae.pkl', 'rb') as f:\n",
    "    data_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a956f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 88.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# select data\n",
    "ver = 1 # 1, 2, 3\n",
    "low_esi = 1 # 0, 1, 'all'\n",
    "data = data_dict[ver][low_esi]\n",
    "n_var = data['trn']['X'].shape[1]\n",
    "\n",
    "# make it as data loaders\n",
    "# building data loader\n",
    "data_loaders = {i:{} for i in ['trn', 'val_tr', 'val_th', 'tst']}\n",
    "for i in tqdm(['trn', 'val_tr', 'val_th', 'tst']):\n",
    "    tmp_X = torch.tensor(data[i]['X'])\n",
    "    tmp_y = torch.tensor(data[i]['y'])\n",
    "    tmp_ids = torch.tensor(data[i]['ids'])\n",
    "    tmp_n_seq = torch.tensor(data[i]['n_seq'])\n",
    "    \n",
    "    batch_size = 256 # 256, 128, 64\n",
    "    data_loaders[i] = DataLoader(dataset=TensorDataset(tmp_X, tmp_y, tmp_ids, tmp_n_seq), batch_size=batch_size if i=='trn' else tmp_X.shape[0] if i=='var_tr' else 1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33ed8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training setting\n",
    "seed_everything(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = Autoencoder(n_var)\n",
    "model = model.to(device)\n",
    "\n",
    "n_epochs=5000\n",
    "factor=0.1\n",
    "patience=100\n",
    "min_lr=1e-6\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=factor, patience=patience, min_lr=min_lr, verbose=True)\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "history = dict(train=[], val=[])\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_loss = float('inf')\n",
    "early_stopping_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "640180b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss 0.16069549501354244 val loss 0.15829475888812702\n",
      "Current learning rate: 0.001\n",
      "early_stopping_counter: 0 \n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    model = model.train()\n",
    "\n",
    "    train_losses = []\n",
    "    for seq_true, _, _, _ in data_loaders['trn']:\n",
    "        seq_true = seq_true.to(device)\n",
    "        seq_pred = model(seq_true)\n",
    "        loss = criterion(seq_pred, seq_true)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    val_losses = []\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        for seq_true, _, _, _ in data_loaders['val_tr']:\n",
    "            seq_true = seq_true.to(device)\n",
    "            seq_pred = model(seq_true)\n",
    "            loss = criterion(seq_pred, seq_true)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "    val_loss = np.mean(val_losses)\n",
    "\n",
    "    history['train'].append(train_loss)\n",
    "    history['val'].append(val_loss)\n",
    "\n",
    "    print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n",
    "\n",
    "    scheduler.step(val_loss)  # 검증 손실을 이용하여 학습률 조절\n",
    "\n",
    "    print(\"Current learning rate:\", optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch} due to no improvement in validation loss.')\n",
    "            break\n",
    "    \n",
    "    print(f'early_stopping_counter: {early_stopping_counter} ')\n",
    "    \n",
    "model.load_state_dict(best_model_wts)\n",
    "torch.save(model.state_dict(), f'model_best-autoencoder-low_esi{ver}-{low_esi}.pth')\n",
    "\n",
    "with open(f'model_history-autoencoder-low_esi{ver}-{low_esi}.pkl', 'wb') as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation data\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "seed_everything(SEED)\n",
    "model = Autoencoder(n_var)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(f'model_best-autoencoder-low_esi{ver}-{low_esi}.pth'))\n",
    "model = model.eval()\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "# loss calculation\n",
    "eval_split = 'val_th' #tst val_th\n",
    "eval_data = []\n",
    "with torch.no_grad():\n",
    "    for seq_true, y, id, n_seq in tqdm(data_loaders[eval_split]):\n",
    "        id = id.cpu().numpy().ravel()[0]\n",
    "        y = y.cpu().numpy().ravel()[0]\n",
    "        seq_true = seq_true.to(device)\n",
    "        seq_pred = model(seq_true)\n",
    "        loss=criterion(seq_pred, seq_true)\n",
    "        \n",
    "        eval_data.append([id, y, loss.item(), n_seq])\n",
    "\n",
    "eval_data = pd.DataFrame(eval_data, columns=['id', 'true', 'score', 'n_seq'])\n",
    "eval_data.to_csv(f\"eval_data-low_esi{ver}-{low_esi}-autoencoder-{eval_split}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149af053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation data\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "seed_everything(SEED)\n",
    "model = Autoencoder(n_var)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(f'model_best-autoencoder-low_esi{ver}-{low_esi}.pth'))\n",
    "model = model.eval()\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "# loss calculation\n",
    "eval_split = 'tst' #tst val_th\n",
    "eval_data = []\n",
    "with torch.no_grad():\n",
    "    for seq_true, y, id, n_seq in tqdm(data_loaders[eval_split]):\n",
    "        id = id.cpu().numpy().ravel()[0]\n",
    "        y = y.cpu().numpy().ravel()[0]\n",
    "        seq_true = seq_true.to(device)\n",
    "        seq_pred = model(seq_true)\n",
    "        loss=criterion(seq_pred, seq_true)\n",
    "        \n",
    "        eval_data.append([id, y, loss.item(), n_seq])\n",
    "\n",
    "eval_data = pd.DataFrame(eval_data, columns=['id', 'true', 'score', 'n_seq'])\n",
    "eval_data.to_csv(f\"eval_data-low_esi{ver}-{low_esi}-autoencoder-{eval_split}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abde0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2652/2652 [00:29<00:00, 90.81it/s]\n"
     ]
    }
   ],
   "source": [
    "def conf_mat(true, pred):\n",
    "    tp = ((pred == 1) & (true == 1)).sum()\n",
    "    fp = ((pred == 1) & (true == 0)).sum()\n",
    "    fn = ((pred == 0) & (true == 1)).sum()\n",
    "    tn = ((pred == 0) & (true == 0)).sum()\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "eval_split = 'val_th' #tst val_th\n",
    "eval_result = []\n",
    "eval_data = pd.read_csv(f\"eval_data-low_esi{ver}-{low_esi}-autoencoder-{eval_split}.csv\")\n",
    "scores = eval_data['score'].unique()\n",
    "\n",
    "for s in tqdm(scores):\n",
    "    eval_data['pred'] = np.where(eval_data['score']>=s, 1, 0)\n",
    "    tmp = eval_data.groupby('id').agg({'true': lambda x: x.values[0], 'pred': 'max'}).reset_index()\n",
    "    tp, fp, fn, tn = conf_mat(tmp['true'], tmp['pred'])\n",
    "\n",
    "    eval_result.append([s, tp/(tp+fn), tp/(tp+fp), 2*tp/(fp+2*tp+fn)])\n",
    "\n",
    "eval_result = pd.DataFrame(eval_result, columns=['score', 'rec', 'prec', 'f1'])\n",
    "eval_result.to_csv(f'eval_result-low_esi{ver}-{low_esi}-autoencoder-{eval_split}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca86094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat(true, pred):\n",
    "    tp = ((pred == 1) & (true == 1)).sum()\n",
    "    fp = ((pred == 1) & (true == 0)).sum()\n",
    "    fn = ((pred == 0) & (true == 1)).sum()\n",
    "    tn = ((pred == 0) & (true == 0)).sum()\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "eval_split = 'tst' #tst val_th\n",
    "eval_result = []\n",
    "eval_data = pd.read_csv(f\"eval_data-low_esi{ver}-{low_esi}-autoencoder-{eval_split}.csv\")\n",
    "scores = eval_data['score'].unique()\n",
    "\n",
    "for s in tqdm(scores):\n",
    "    eval_data['pred'] = np.where(eval_data['score']>=s, 1, 0)\n",
    "    tmp = eval_data.groupby('id').agg({'true': lambda x: x.values[0], 'pred': 'max'}).reset_index()\n",
    "    tp, fp, fn, tn = conf_mat(tmp['true'], tmp['pred'])\n",
    "\n",
    "    eval_result.append([s, tp/(tp+fn), tp/(tp+fp), 2*tp/(fp+2*tp+fn)])\n",
    "\n",
    "eval_result = pd.DataFrame(eval_result, columns=['score', 'rec', 'prec', 'f1'])\n",
    "eval_result.to_csv(f'eval_result-low_esi{ver}-{low_esi}-autoencoder-{eval_split}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a5eba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_torch_py39",
   "language": "python",
   "name": "torch_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
