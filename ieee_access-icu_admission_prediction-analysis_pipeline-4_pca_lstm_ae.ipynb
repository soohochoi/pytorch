{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T00:39:20.054895100Z",
     "start_time": "2024-02-07T00:39:18.958157900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load modules and set configurations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, copy, random, pickle, gc\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870f4c14",
   "metadata": {},
   "source": [
    "# 4. pca LSTM Auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "788efdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F \n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, seq_len, n_features, embedding_dim=64):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.seq_len, self.n_features = seq_len, n_features\n",
    "    self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n",
    "    self.rnn1 = nn.LSTM(\n",
    "      input_size=n_features,\n",
    "      hidden_size=self.hidden_dim,\n",
    "      num_layers=1,\n",
    "      batch_first=True\n",
    "    )\n",
    "    self.rnn2 = nn.LSTM(\n",
    "      input_size=self.hidden_dim,\n",
    "      hidden_size=embedding_dim,\n",
    "      num_layers=1,\n",
    "      batch_first=True\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x, (_, _) = self.rnn1(x)\n",
    "    x, (hidden_n, _) = self.rnn2(x)\n",
    "    return hidden_n.reshape((-1,1, self.embedding_dim))\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, seq_len, input_dim=64, n_features=114):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.seq_len, self.input_dim = seq_len, input_dim\n",
    "    self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
    "    self.rnn1 = nn.LSTM(\n",
    "      input_size=input_dim,\n",
    "      hidden_size=input_dim,\n",
    "      num_layers=1,\n",
    "      batch_first=True\n",
    "    )\n",
    "    self.rnn2 = nn.LSTM(\n",
    "      input_size=input_dim,\n",
    "      hidden_size=self.hidden_dim,\n",
    "      num_layers=1,\n",
    "      batch_first=True\n",
    "    )\n",
    "    self.output_layer = nn.Linear(self.hidden_dim, n_features)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.repeat(1,self.seq_len, 1)\n",
    "    x, (hidden_n, cell_n) = self.rnn1(x)\n",
    "    x, (hidden_n, cell_n) = self.rnn2(x)\n",
    "    return self.output_layer(x)\n",
    "\n",
    "class RecurrentAutoencoder(nn.Module):\n",
    "  def __init__(self, seq_len, n_features, embedding_dim=64):\n",
    "    super(RecurrentAutoencoder, self).__init__()\n",
    "    self.encoder = Encoder(seq_len, n_features, embedding_dim).to(device)\n",
    "    self.decoder = Decoder(seq_len, embedding_dim, n_features).to(device)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.encoder(x)\n",
    "    x = self.decoder(x)\n",
    "\n",
    "    return x\n",
    "  \n",
    "with open(f'data-dict-for_pca_lstm_ae.pkl', 'rb') as f:\n",
    "    data_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "609e9863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 85.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# select data\n",
    "ver = 2 # 1, 2, 3\n",
    "low_esi = 1 # 0, 1, 'all'\n",
    "data = data_dict[ver][low_esi]\n",
    "_, max_seq_len, n_var = data['trn']['X'].shape\n",
    "\n",
    "# make it as data loaders\n",
    "# building data loader\n",
    "data_loaders = {i:{} for i in ['trn', 'val_tr', 'val_th', 'tst']}\n",
    "for i in tqdm(['trn', 'val_tr', 'val_th', 'tst']):\n",
    "    tmp_X = torch.tensor(data[i]['X'].astype(np.float32))\n",
    "    tmp_y = torch.tensor(data[i]['y'].astype(int))\n",
    "    tmp_ids = torch.tensor(data[i]['ids'].astype(int))\n",
    "    tmp_n_seq = torch.tensor(data[i]['n_seq'].astype(int))\n",
    "    \n",
    "    batch_size = 256 # 256, 128, 64\n",
    "    data_loaders[i] = DataLoader(dataset=TensorDataset(tmp_X, tmp_y, tmp_ids, tmp_n_seq), batch_size=batch_size if i=='trn' else tmp_X.shape[0] if i=='var_tr' else 1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "39a4c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training setting\n",
    "seed_everything(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "hidden_unit = 16\n",
    "n_epochs, factor, patience, min_lr = (5000, 0.1, 100, 1e-6)\n",
    "loss_reduction = 'global_mean'\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "model = RecurrentAutoencoder(max_seq_len, n_var, hidden_unit)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=factor, patience=patience, min_lr=min_lr, verbose=True)\n",
    "criterion = nn.MSELoss(reduction='none').to(device)\n",
    "\n",
    "history = dict(train=[], val=[])\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_loss = float('inf')\n",
    "early_stopping_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c60d7494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss 2.0138311887900513 val loss 0.8700017681534772\n",
      "Current learning rate: 0.001\n",
      "early_stopping_counter: 0 \n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    model = model.train()\n",
    "\n",
    "    train_losses = []\n",
    "    for seq_true, _, _, _ in data_loaders['trn']:\n",
    "        seq_true = seq_true.to(device)\n",
    "        mask = ~torch.all(seq_true==0, axis=2)\n",
    "        seq_pred = model(seq_true)\n",
    "\n",
    "        if loss_reduction == 'stay_wise_mean':\n",
    "            l = criterion(seq_pred[mask], seq_true[mask]).sum(axis=1)\n",
    "            lens = mask.sum(axis=1).detach().cpu()\n",
    "            c_lens = lens.cumsum(dim=0)\n",
    "            loss = 0\n",
    "            for idx, i in enumerate(c_lens):\n",
    "                s = 0 if idx == 0 else c_lens[idx-1]\n",
    "                loss += l[s:c_lens[idx]].sum()/lens[idx]\n",
    "        elif loss_reduction == 'global_mean':\n",
    "            l = criterion(seq_pred[mask], seq_true[mask]).sum()\n",
    "            loss = l/mask.sum()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    val_losses = []\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        for seq_true, _, _, _ in data_loaders['val_tr']:\n",
    "            seq_true = seq_true.to(device)\n",
    "            mask = ~torch.all(seq_true==0, axis=2)\n",
    "            seq_pred = model(seq_true)\n",
    "\n",
    "            if loss_reduction == 'stay_wise_mean':\n",
    "                l = criterion(seq_pred[mask], seq_true[mask]).sum(axis=1)\n",
    "                lens = mask.sum(axis=1).detach().cpu()\n",
    "                c_lens = lens.cumsum(dim=0)\n",
    "                loss = 0\n",
    "                for idx, i in enumerate(c_lens):\n",
    "                    s = 0 if idx == 0 else c_lens[idx-1]\n",
    "                    loss += l[s:c_lens[idx]].sum()/lens[idx]\n",
    "            elif loss_reduction == 'global_mean':\n",
    "                l = criterion(seq_pred[mask], seq_true[mask]).sum()\n",
    "                loss = l/mask.sum()\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "    val_loss = np.mean(val_losses)\n",
    "\n",
    "    history['train'].append(train_loss)\n",
    "    history['val'].append(val_loss)\n",
    "\n",
    "    print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Current learning rate:\", optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch} due to no improvement in validation loss.')\n",
    "            break\n",
    "    \n",
    "    print(f'early_stopping_counter: {early_stopping_counter} ')\n",
    "    \n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "torch.save(model.state_dict(), f'model_best-lstm_ae_pca-low_esi{ver}-{low_esi}.pth')\n",
    "\n",
    "with open(f'model_history-lstm_ae_pca-low_esi{ver}-{low_esi}.pkl', 'wb') as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fd1af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation data\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "seed_everything(SEED)\n",
    "hidden_unit = 16\n",
    "\n",
    "model = RecurrentAutoencoder(max_seq_len, n_var, hidden_unit)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(f'model_best-lstm_ae_pca-low_esi{ver}-{low_esi}.pth'))\n",
    "model = model.eval()\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "# loss calculation\n",
    "eval_split = 'val_th' #tst val_th\n",
    "\n",
    "eval_data = []\n",
    "with torch.no_grad():\n",
    "    for seq_true, y, id, n_seq in tqdm(data_loaders[eval_split]):\n",
    "        id = id.cpu().numpy().ravel()[0]\n",
    "        y = y.cpu().numpy().ravel()[0]\n",
    "        seq_true = seq_true.to(device)\n",
    "        seq_pred = model(seq_true)\n",
    "        loss=criterion(seq_pred, seq_true)\n",
    "        \n",
    "        eval_data.append([id, y, loss.item(), n_seq])\n",
    "\n",
    "eval_data = pd.DataFrame(eval_data, columns=['id', 'true', 'score', 'n_seq'])\n",
    "eval_data.to_csv(f\"eval_data-low_esi{ver}-{low_esi}-lstm_ae_pca-{eval_split}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f2056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation data\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "seed_everything(SEED)\n",
    "hidden_unit = 16\n",
    "\n",
    "model = RecurrentAutoencoder(max_seq_len, n_var, hidden_unit)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(f'model_best-lstm_ae_pca-low_esi{ver}-{low_esi}.pth'))\n",
    "model = model.eval()\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "# loss calculation\n",
    "eval_split = 'tst' #tst val_th\n",
    "\n",
    "eval_data = []\n",
    "with torch.no_grad():\n",
    "    for seq_true, y, id, n_seq in tqdm(data_loaders[eval_split]):\n",
    "        id = id.cpu().numpy().ravel()[0]\n",
    "        y = y.cpu().numpy().ravel()[0]\n",
    "        seq_true = seq_true.to(device)\n",
    "        seq_pred = model(seq_true)\n",
    "        loss=criterion(seq_pred, seq_true)\n",
    "        \n",
    "        eval_data.append([id, y, loss.item(), n_seq])\n",
    "\n",
    "eval_data = pd.DataFrame(eval_data, columns=['id', 'true', 'score', 'n_seq'])\n",
    "eval_data.to_csv(f\"eval_data-low_esi{ver}-{low_esi}-lstm_ae_pca-{eval_split}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e800ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_split = 'val_th' #tst val_th\n",
    "def conf_mat(true, pred):\n",
    "    tp = ((pred == 1) & (true == 1)).sum()\n",
    "    fp = ((pred == 1) & (true == 0)).sum()\n",
    "    fn = ((pred == 0) & (true == 1)).sum()\n",
    "    tn = ((pred == 0) & (true == 0)).sum()\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "eval_result = []\n",
    "eval_data = pd.read_csv(f\"eval_data-low_esi{ver}-{low_esi}-{\"lstm_ae_pca\"}-{eval_split}.csv\")\n",
    "scores = eval_data['score'].unique()\n",
    "\n",
    "for s in tqdm(scores):\n",
    "    eval_data['pred'] = np.where(eval_data['score']>=s, 1, 0)\n",
    "    tmp = eval_data.groupby('id').agg({'true': lambda x: x.values[0], 'pred': 'max'}).reset_index()\n",
    "    tp, fp, fn, tn = conf_mat(tmp['true'], tmp['pred'])\n",
    "\n",
    "    eval_result.append([s, tp/(tp+fn), tp/(tp+fp), 2*tp/(fp+2*tp+fn)])\n",
    "\n",
    "eval_result = pd.DataFrame(eval_result, columns=['score', 'rec', 'prec', 'f1'])\n",
    "eval_result.to_csv(f'eval_result-low_esi{ver}-{low_esi}-{\"lstm_ae_pca\"}-{eval_split}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8905337",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_split = 'tst' #tst val_th\n",
    "def conf_mat(true, pred):\n",
    "    tp = ((pred == 1) & (true == 1)).sum()\n",
    "    fp = ((pred == 1) & (true == 0)).sum()\n",
    "    fn = ((pred == 0) & (true == 1)).sum()\n",
    "    tn = ((pred == 0) & (true == 0)).sum()\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "eval_result = []\n",
    "eval_data = pd.read_csv(f\"eval_data-low_esi{ver}-{low_esi}-{\"lstm_ae_pca\"}-{eval_split}.csv\")\n",
    "scores = eval_data['score'].unique()\n",
    "\n",
    "for s in tqdm(scores):\n",
    "    eval_data['pred'] = np.where(eval_data['score']>=s, 1, 0)\n",
    "    tmp = eval_data.groupby('id').agg({'true': lambda x: x.values[0], 'pred': 'max'}).reset_index()\n",
    "    tp, fp, fn, tn = conf_mat(tmp['true'], tmp['pred'])\n",
    "\n",
    "    eval_result.append([s, tp/(tp+fn), tp/(tp+fp), 2*tp/(fp+2*tp+fn)])\n",
    "\n",
    "eval_result = pd.DataFrame(eval_result, columns=['score', 'rec', 'prec', 'f1'])\n",
    "eval_result.to_csv(f'eval_result-low_esi{ver}-{low_esi}-{\"lstm_ae_pca\"}-{eval_split}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddfd060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_torch_py39",
   "language": "python",
   "name": "torch_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
