{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-26T04:17:36.038312600Z",
     "start_time": "2023-12-26T04:17:34.527682300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "#from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_1=pd.read_csv('ED_3hour_foward_full.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T04:49:08.976737400Z",
     "start_time": "2023-12-26T04:48:37.815334200Z"
    }
   },
   "id": "fc2de7f8f41cebdc"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "name=\"label_after_2hour\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:37:40.920568500Z",
     "start_time": "2023-12-26T06:37:40.882913500Z"
    }
   },
   "id": "3c0ce61f8aac55f0"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "#df_1=df_1[~df_1['stay_id'].isin(df_1[df_1[name]==2]['stay_id'].unique())]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:37:43.733024700Z",
     "start_time": "2023-12-26T06:37:43.716801400Z"
    }
   },
   "id": "5a9e151a2463a2a2"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "#df_1.loc[df_1[name] == 1, name] = 0\n",
    "#df_1.loc[df_1[name] == 2, name] = 0\n",
    "#df_1.loc[df_1[name] == 3, name] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:37:43.755476400Z",
     "start_time": "2023-12-26T06:37:43.733024700Z"
    }
   },
   "id": "4886f14ee67ae2cc"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "icu_samples = df_1[df_1[name] == 3]\n",
    "hos_samples = df_1[df_1[name] == 2]\n",
    "\n",
    "icu_stay_id = icu_samples['stay_id'].unique()\n",
    "\n",
    "train_icu_stay_id, icu_temp_stay_id = train_test_split(icu_stay_id, test_size=0.2, random_state=42)\n",
    "test_icu_stay_id, val_icu_stay_id = train_test_split(icu_temp_stay_id, test_size=0.2, random_state=42)\n",
    "\n",
    "train_icu_data = df_1[df_1['stay_id'].isin(train_icu_stay_id)]\n",
    "test_icu_data = df_1[df_1['stay_id'].isin(test_icu_stay_id)]\n",
    "val_icu_data = df_1[df_1['stay_id'].isin(val_icu_stay_id)]\n",
    "\n",
    "hos_stay_id = hos_samples['stay_id'].unique()\n",
    "\n",
    "train_hos_stay_id, hos_temp_stay_id = train_test_split(hos_stay_id, test_size=0.2, random_state=42)\n",
    "test_hos_stay_id, val_hos_stay_id = train_test_split(hos_temp_stay_id, test_size=0.2, random_state=42)\n",
    "\n",
    "train_hos_data = df_1[df_1['stay_id'].isin(train_hos_stay_id)]\n",
    "test_hos_data = df_1[df_1['stay_id'].isin(test_hos_stay_id)]\n",
    "val_hos_data = df_1[df_1['stay_id'].isin(val_hos_stay_id)]\n",
    "\n",
    "ed_data=df_1[~df_1['stay_id'].isin(list(icu_stay_id)+list(hos_stay_id))]\n",
    "\n",
    "train_ed_stay_id, ed_temp_stay_id = train_test_split(ed_data['stay_id'].unique(), test_size=0.2, random_state=42)\n",
    "test_ed_stay_id, val_ed_stay_id = train_test_split(ed_temp_stay_id, test_size=0.2, random_state=42)\n",
    "\n",
    "train_ed_data = df_1[df_1['stay_id'].isin(train_ed_stay_id)]\n",
    "test_ed_data = df_1[df_1['stay_id'].isin(test_ed_stay_id)]\n",
    "val_ed_data = df_1[df_1['stay_id'].isin(val_ed_stay_id)]\n",
    "\n",
    "train_df = pd.concat([train_icu_data, train_hos_data, train_ed_data ])\n",
    "test_df = pd.concat([test_icu_data, test_hos_data, test_ed_data])\n",
    "val_df = pd.concat([val_icu_data, val_hos_data, val_ed_data])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:37:51.839680100Z",
     "start_time": "2023-12-26T06:37:43.748403600Z"
    }
   },
   "id": "e2752743b515d664"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "#list(icu_stay_id)+list(hos_stay_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:37:51.854073100Z",
     "start_time": "2023-12-26T06:37:51.839680100Z"
    }
   },
   "id": "efbfa8ef2bb7c6dd"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "train_df=train_df.sort_index()\n",
    "test_df=test_df.sort_index()\n",
    "val_df=val_df.sort_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:37:54.384420700Z",
     "start_time": "2023-12-26T06:37:51.857450300Z"
    }
   },
   "id": "1ca99dc4dcf9a17c"
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "            stay_id                 time   max_temp  max_hr  max_resp  \\\n0        30000012.0  2126-02-14 21:22:00  37.111111    96.0      18.0   \n1        30000012.0  2126-02-14 22:22:00  37.111111    96.0      18.0   \n2        30000012.0  2126-02-14 23:22:00  37.111111    96.0      18.0   \n3        30000012.0  2126-02-15 00:22:00  37.111111    80.0      13.0   \n4        30000012.0  2126-02-15 01:22:00  37.000000    88.0      16.0   \n...             ...                  ...        ...     ...       ...   \n7149067  39999835.0                    0   0.000000     0.0       0.0   \n7149068  39999835.0                    0   0.000000     0.0       0.0   \n7149069  39999835.0                    0   0.000000     0.0       0.0   \n7149070  39999835.0                    0   0.000000     0.0       0.0   \n7149071  39999835.0                    0   0.000000     0.0       0.0   \n\n         max_o2sat  max_sbp  max_dbp   min_temp  min_hr  ...  \\\n0             93.0    160.0     54.0  37.111111    96.0  ...   \n1             93.0    160.0     54.0  37.111111    96.0  ...   \n2             93.0    160.0     54.0  37.111111    96.0  ...   \n3             99.0    112.0     44.0  37.111111    80.0  ...   \n4            100.0    135.0     51.0  37.000000    80.0  ...   \n...            ...      ...      ...        ...     ...  ...   \n7149067        0.0      0.0      0.0   0.000000     0.0  ...   \n7149068        0.0      0.0      0.0   0.000000     0.0  ...   \n7149069        0.0      0.0      0.0   0.000000     0.0  ...   \n7149070        0.0      0.0      0.0   0.000000     0.0  ...   \n7149071        0.0      0.0      0.0   0.000000     0.0  ...   \n\n         label_after_6hour  gender_F  gender_M  race_Black  race_Other  \\\n0                      2.0         1         0           0           0   \n1                      2.0         1         0           0           0   \n2                      2.0         1         0           0           0   \n3                      2.0         1         0           0           0   \n4                      2.0         1         0           0           0   \n...                    ...       ...       ...         ...         ...   \n7149067                0.0         0         0           0           0   \n7149068                0.0         0         0           0           0   \n7149069                0.0         0         0           0           0   \n7149070                0.0         0         0           0           0   \n7149071                0.0         0         0           0           0   \n\n         race_White  arrival_transport_AMBULANCE  \\\n0                 1                            1   \n1                 1                            1   \n2                 1                            1   \n3                 1                            1   \n4                 1                            1   \n...             ...                          ...   \n7149067           0                            0   \n7149068           0                            0   \n7149069           0                            0   \n7149070           0                            0   \n7149071           0                            0   \n\n         arrival_transport_HELICOPTER  arrival_transport_OTHER  \\\n0                                   0                        0   \n1                                   0                        0   \n2                                   0                        0   \n3                                   0                        0   \n4                                   0                        0   \n...                               ...                      ...   \n7149067                             0                        0   \n7149068                             0                        0   \n7149069                             0                        0   \n7149070                             0                        0   \n7149071                             0                        0   \n\n         arrival_transport_WALK IN  \n0                                0  \n1                                0  \n2                                0  \n3                                0  \n4                                0  \n...                            ...  \n7149067                          0  \n7149068                          0  \n7149069                          0  \n7149070                          0  \n7149071                          0  \n\n[5719296 rows x 122 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stay_id</th>\n      <th>time</th>\n      <th>max_temp</th>\n      <th>max_hr</th>\n      <th>max_resp</th>\n      <th>max_o2sat</th>\n      <th>max_sbp</th>\n      <th>max_dbp</th>\n      <th>min_temp</th>\n      <th>min_hr</th>\n      <th>...</th>\n      <th>label_after_6hour</th>\n      <th>gender_F</th>\n      <th>gender_M</th>\n      <th>race_Black</th>\n      <th>race_Other</th>\n      <th>race_White</th>\n      <th>arrival_transport_AMBULANCE</th>\n      <th>arrival_transport_HELICOPTER</th>\n      <th>arrival_transport_OTHER</th>\n      <th>arrival_transport_WALK IN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30000012.0</td>\n      <td>2126-02-14 21:22:00</td>\n      <td>37.111111</td>\n      <td>96.0</td>\n      <td>18.0</td>\n      <td>93.0</td>\n      <td>160.0</td>\n      <td>54.0</td>\n      <td>37.111111</td>\n      <td>96.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30000012.0</td>\n      <td>2126-02-14 22:22:00</td>\n      <td>37.111111</td>\n      <td>96.0</td>\n      <td>18.0</td>\n      <td>93.0</td>\n      <td>160.0</td>\n      <td>54.0</td>\n      <td>37.111111</td>\n      <td>96.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30000012.0</td>\n      <td>2126-02-14 23:22:00</td>\n      <td>37.111111</td>\n      <td>96.0</td>\n      <td>18.0</td>\n      <td>93.0</td>\n      <td>160.0</td>\n      <td>54.0</td>\n      <td>37.111111</td>\n      <td>96.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30000012.0</td>\n      <td>2126-02-15 00:22:00</td>\n      <td>37.111111</td>\n      <td>80.0</td>\n      <td>13.0</td>\n      <td>99.0</td>\n      <td>112.0</td>\n      <td>44.0</td>\n      <td>37.111111</td>\n      <td>80.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30000012.0</td>\n      <td>2126-02-15 01:22:00</td>\n      <td>37.000000</td>\n      <td>88.0</td>\n      <td>16.0</td>\n      <td>100.0</td>\n      <td>135.0</td>\n      <td>51.0</td>\n      <td>37.000000</td>\n      <td>80.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7149067</th>\n      <td>39999835.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7149068</th>\n      <td>39999835.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7149069</th>\n      <td>39999835.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7149070</th>\n      <td>39999835.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7149071</th>\n      <td>39999835.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5719296 rows × 122 columns</p>\n</div>"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:37:55.960393500Z",
     "start_time": "2023-12-26T06:37:54.432615500Z"
    }
   },
   "id": "f33fb3381d0a9ca8"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238304\n",
      "47661\n",
      "11916\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df['stay_id'].unique()))\n",
    "print(len(test_df['stay_id'].unique()))\n",
    "print(len(val_df['stay_id'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:37:56.095284500Z",
     "start_time": "2023-12-26T06:37:55.960393500Z"
    }
   },
   "id": "7fcf91ac6055669b"
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "train_x=train_df.drop(['stay_id','time','label_after_1hour','label_after_2hour','label_after_3hour','label_after_4hour','label_after_5hour','label_after_6hour'],axis='columns')\n",
    "train_y=train_df[name]\n",
    "test_x=test_df.drop(['stay_id','time','label_after_1hour','label_after_2hour','label_after_3hour','label_after_4hour','label_after_5hour','label_after_6hour'],axis='columns')\n",
    "test_y=test_df[name]\n",
    "val_x=val_df.drop(['stay_id','time','label_after_1hour','label_after_2hour','label_after_3hour','label_after_4hour','label_after_5hour','label_after_6hour'],axis='columns')\n",
    "val_y=val_df[name]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:37:57.869727800Z",
     "start_time": "2023-12-26T06:37:56.069380900Z"
    }
   },
   "id": "e74f0a575daedb70"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "train_x = train_x.astype(np.float32)\n",
    "train_y = train_y.astype(np.float32)\n",
    "test_x = test_x.astype(np.float32)\n",
    "test_y = test_y.astype(np.float32)\n",
    "val_x = val_x.astype(np.float32)\n",
    "val_y = val_y.astype(np.float32)\n",
    "train_x = train_x.to_numpy()\n",
    "train_y = train_y.to_numpy()\n",
    "test_x = test_x.to_numpy()\n",
    "test_y = test_y.to_numpy()\n",
    "val_x = val_x.to_numpy()\n",
    "val_y = val_y.to_numpy()\n",
    "train_data_x_reshaped = train_x.reshape((len(train_df['stay_id'].unique()), 24, 114))\n",
    "train_data_y_reshaped = train_y.reshape((len(train_df['stay_id'].unique()), 24,1))\n",
    "test_data_x_reshaped = test_x.reshape((len(test_df['stay_id'].unique()), 24, 114))\n",
    "test_data_y_reshaped = test_y.reshape((len(test_df['stay_id'].unique()), 24, 1))\n",
    "val_x_reshaped = val_x.reshape((len(val_df['stay_id'].unique()), 24, 114))\n",
    "val_y_reshaped = val_y.reshape((len(val_df['stay_id'].unique()), 24, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:38:01.319379400Z",
     "start_time": "2023-12-26T06:37:57.869727800Z"
    }
   },
   "id": "46e331a1f053080c"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "(238304, 24, 1)"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_y_reshaped.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:38:01.343705400Z",
     "start_time": "2023-12-26T06:38:01.323708400Z"
    }
   },
   "id": "b1872b5a39d470d8"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "largest_values = np.max(train_data_y_reshaped, axis=1, keepdims=True) \n",
    "train_data_y_reshaped_1 = largest_values.reshape(len(train_df['stay_id'].unique()), 1, 1)\n",
    "\n",
    "largest_values = np.max(test_data_y_reshaped, axis=1, keepdims=True) \n",
    "test_data_y_reshaped_1 = largest_values.reshape(len(test_df['stay_id'].unique()), 1, 1)\n",
    "\n",
    "largest_values = np.max(val_y_reshaped, axis=1, keepdims=True) \n",
    "val_y_reshaped_1 = largest_values.reshape(len(val_df['stay_id'].unique()), 1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:38:01.489760Z",
     "start_time": "2023-12-26T06:38:01.338405300Z"
    }
   },
   "id": "b5d052b9510c023b"
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Assuming you have three classes\n",
    "num_classes = 4\n",
    "\n",
    "# For train data\n",
    "largest_values_train = np.max(train_data_y_reshaped, axis=1, keepdims=True)\n",
    "train_data_y_reshaped_1 = to_categorical(largest_values_train, num_classes=num_classes)\n",
    "\n",
    "# For test data\n",
    "largest_values_test = np.max(test_data_y_reshaped, axis=1, keepdims=True)\n",
    "test_data_y_reshaped_1 = to_categorical(largest_values_test, num_classes=num_classes)\n",
    "\n",
    "# For validation data\n",
    "largest_values_val = np.max(val_y_reshaped, axis=1, keepdims=True)\n",
    "val_y_reshaped_1 = to_categorical(largest_values_val, num_classes=num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:38:01.524505400Z",
     "start_time": "2023-12-26T06:38:01.491031700Z"
    }
   },
   "id": "b5558aaf0c7a69e0"
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "train_data_y_reshaped_1=train_data_y_reshaped_1.reshape(-1,4)\n",
    "test_data_y_reshaped_1=test_data_y_reshaped_1.reshape(-1,4)\n",
    "val_y_reshaped_1=val_y_reshaped_1.reshape(-1,4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:38:01.547234Z",
     "start_time": "2023-12-26T06:38:01.522900900Z"
    }
   },
   "id": "837842a53c8e52f3"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "(238304, 24, 114)"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_x_reshaped.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:38:01.659066Z",
     "start_time": "2023-12-26T06:38:01.538423100Z"
    }
   },
   "id": "51a74dda81ccd812"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.tensor(train_data_x_reshaped),torch.tensor(train_data_y_reshaped_1)) \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True) \n",
    "\n",
    "valid_dataset = TensorDataset(torch.tensor(val_x_reshaped),torch.tensor(val_y_reshaped_1))\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(torch.tensor(test_data_x_reshaped),torch.tensor(test_data_y_reshaped_1)) \n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:38:02.206720100Z",
     "start_time": "2023-12-26T06:38:01.561326200Z"
    }
   },
   "id": "bfe9d95bacbc0cde"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:38:02.235829500Z",
     "start_time": "2023-12-26T06:38:02.191558Z"
    }
   },
   "id": "e1c63633098d9a61"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "sequence_length = 24 # \n",
    "feature_size = 114 # \n",
    "hidden_size = 128 # Hidden Layer 사이즈 설정처럼 설정\n",
    "num_layers = 4 # stacked RNN (최대 4개까지는 Gradient Vanishing 현상이 적을 수 있으므로)\n",
    "dropout_p = 0.2 # dropout rate\n",
    "output_size = 4 # \n",
    "#minibatch_size = 128 # minibatch_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:38:02.250562800Z",
     "start_time": "2023-12-26T06:38:02.208730600Z"
    }
   },
   "id": "85228aba35629eb7"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, feature_size, hidden_size, num_layers, dropout_p, output_size, model_type):\n",
    "        super().__init__()\n",
    "        if model_type == 'rnn':\n",
    "            self.sequenceclassifier = nn.RNN(\n",
    "                input_size = feature_size,\n",
    "                hidden_size = hidden_size,\n",
    "                num_layers = num_layers,\n",
    "                batch_first = True,\n",
    "                dropout = dropout_p,\n",
    "                bidirectional = True\n",
    "            )\n",
    "        elif model_type == 'lstm':\n",
    "            self.sequenceclassifier = nn.LSTM(\n",
    "                input_size = feature_size,\n",
    "                hidden_size = hidden_size,\n",
    "                num_layers = num_layers,\n",
    "                batch_first = True,\n",
    "                dropout = dropout_p,\n",
    "                bidirectional = True\n",
    "            )\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.BatchNorm1d(hidden_size * 2),\n",
    "            # self.rnn() 의 출력값은 (batch_size, sequence_length, bidirections * hidden_size)\n",
    "            # bidirectional 이 True 이므로, bidirections 는 2, 즉 2 * hidden_size\n",
    "            nn.Linear(hidden_size * 2, output_size),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # |x| = batch_first=True 이므로 (batch_size, sequence_length, input_size)\n",
    "        out, _ = self.sequenceclassifier(x) # output, h_n 이므로, h_n 은 사용안함\n",
    "        # output, h_n 이므로, h_n 은 사용안함\n",
    "        # |out| = batch_first=True 이므로 (batch_size, sequence_length, 2 * hidden_size)\n",
    "        # bidirectional 이 True 이면, bidirections 는 2 * hidden_size\n",
    "        out = out[:, -1]\n",
    "        # out[:, -1] 은 (batch_size, sequence_length, 2 * hidden_size) 에서, \n",
    "        # 전체 batch_size 를 선택한다는 의미가 :, \n",
    "        # sequence_length 인 28개의 순서가 있고, 각 순서마다 2 * hidden_size 만큼 있음\n",
    "        # 이중에 최종 값은 맨 마지막  sequence_length 의 2 * hidden_size 임\n",
    "        # |out| = (batch_size, hidden_size * 2)\n",
    "        y = self.layers(out)\n",
    "        # |y| = (batch_size, output_size)\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:38:02.298327800Z",
     "start_time": "2023-12-26T06:38:02.225694100Z"
    }
   },
   "id": "24929051bec705f0"
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "Net(\n  (sequenceclassifier): LSTM(114, 128, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n  (layers): Sequential(\n    (0): LeakyReLU(negative_slope=0.1)\n    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Linear(in_features=256, out_features=4, bias=True)\n    (3): LogSoftmax(dim=-1)\n  )\n)"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(feature_size, hidden_size, num_layers, dropout_p, output_size, 'lstm').to(device)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T06:38:02.317543Z",
     "start_time": "2023-12-26T06:38:02.237945400Z"
    }
   },
   "id": "4771e499fc10d79a"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5593864692237016 1.0494960476743413 1.0494960476743413 0 0\n",
      "0.4928057258738611 0.9434687996164282 0.4810644044203961 1 3\n",
      "0.489578503014962 0.671127736251405 0.4760943524380948 4 6\n",
      "0.4877077256890552 0.4731477181962196 0.4731477181962196 9 9\n",
      "0.48673165047783346 0.5648033070437452 0.4731477181962196 9 12\n",
      "0.4852316913011891 0.5658165308389258 0.4731477181962196 9 15\n",
      "0.4850455620010993 0.6490441801700186 0.4707200051622188 16 18\n",
      "0.4843041770536328 0.47334982645004353 0.4707200051622188 16 21\n",
      "0.4850391830236648 0.47747777687742354 0.4707200051622188 16 24\n",
      "0.48402888343042255 0.6754174765120161 0.4707200051622188 16 27\n",
      "0.4840970302018648 0.9334656038182847 0.4707200051622188 16 30\n",
      "0.4846900594285684 0.5889445181856764 0.4707200051622188 16 33\n",
      "0.4844467827988234 0.48475199050091683 0.4707200051622188 16 36\n",
      "0.48404937993763086 0.4934372435858909 0.4707200051622188 16 39\n",
      "0.48281675335479984 0.5095708611163687 0.4707200051622188 16 42\n",
      "0.48160149272287184 0.4641695133549102 0.4641695133549102 45 45\n",
      "0.4795999086504976 0.5866208409375333 0.4641695133549102 45 48\n",
      "0.47964387117343865 0.47671947200247583 0.4641695133549102 45 51\n",
      "0.4789341614210516 0.49996835595749795 0.4641695133549102 45 54\n",
      "0.4789265146124888 0.48643410792376135 0.4641695133549102 45 57\n",
      "0.4780338211295172 0.5123329013586044 0.4641695133549102 45 60\n",
      "0.4772085140746339 0.963165395437403 0.4641695133549102 45 63\n",
      "0.4759887785647789 0.4776169312127093 0.4641695133549102 45 66\n",
      "0.47569897457172994 0.7056607172844258 0.4641695133549102 45 69\n",
      "0.47520404690766566 0.6237121940927303 0.4641695133549102 45 72\n",
      "0.47535721333467357 0.6924133953895975 0.4641695133549102 45 75\n",
      "Early Stopped 76 epochs\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "loss_func = nn.NLLLoss() # log softmax 는 NLLLoss() 로 진행해야 함\n",
    "optimizer = torch.optim.Adam(model.parameters()) # Adam, learning rate 필요없음\n",
    "\n",
    "def train_model(model, early_stop, n_epochs, progress_interval):\n",
    "    \n",
    "    train_losses, valid_losses, lowest_loss = list(), list(), np.inf\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        train_loss, valid_loss = 0, 0\n",
    "        \n",
    "        # train the model\n",
    "        model.train() # prep model for training\n",
    "        for x_minibatch, y_minibatch in train_dataloader:\n",
    "            x_minibatch, y_minibatch = x_minibatch.to(device), y_minibatch.to(device) \n",
    "            #y_minibatch = y_minibatch.to(device)    \n",
    "            #mask = torch.sum(x_minibatch, axis = 1)\n",
    "            #mask[mask>0] = 1\n",
    "            y_minibatch_pred = model(x_minibatch)\n",
    "            y_minibatch_indices = torch.argmax(y_minibatch, dim=1) \n",
    "            loss = loss_func(y_minibatch_pred , y_minibatch_indices )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss = train_loss / len(train_dataloader)\n",
    "        train_losses.append(train_loss)      \n",
    "        \n",
    "        # validate the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_minibatch, y_minibatch in valid_dataloader:\n",
    "                x_minibatch, y_minibatch = x_minibatch.to(device), y_minibatch.to(device) \n",
    "                #x_minibatch = x_minibatch.to(device)\n",
    "                #y_minibatch = y_minibatch.to(device)      \n",
    "                #mask = torch.sum(x_minibatch, axis = 1)\n",
    "                #mask[mask>0] = 1\n",
    "                y_minibatch_pred = model(x_minibatch)\n",
    "                y_minibatch_indices = torch.argmax(y_minibatch, dim=1) \n",
    "                loss = loss_func(y_minibatch_pred , y_minibatch_indices )\n",
    "                #loss = loss_func(y_minibatch_pred , y_minibatch )\n",
    "                valid_loss += loss.item()\n",
    "                \n",
    "        valid_loss = valid_loss / len(valid_dataloader)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        if valid_losses[-1] < lowest_loss:\n",
    "            lowest_loss = valid_losses[-1]\n",
    "            lowest_epoch = epoch\n",
    "            best_model = deepcopy(model.state_dict())\n",
    "        else:\n",
    "            if (early_stop > 0) and lowest_epoch + early_stop < epoch:\n",
    "                print (\"Early Stopped\", epoch, \"epochs\")\n",
    "                break\n",
    "                \n",
    "        if (epoch % progress_interval) == 0:\n",
    "            print (train_losses[-1], valid_losses[-1], lowest_loss, lowest_epoch, epoch)\n",
    "            \n",
    "    model.load_state_dict(best_model)        \n",
    "    return model, lowest_loss, train_losses, valid_losses\n",
    "\n",
    "nb_epochs = 100 \n",
    "progress_interval = 3\n",
    "early_stop = 30\n",
    "\n",
    "model, lowest_loss, train_losses, valid_losses = train_model(model, early_stop, nb_epochs, progress_interval)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T07:00:50.252768Z",
     "start_time": "2023-12-26T06:38:02.278357500Z"
    }
   },
   "id": "5d4316c81cd51090"
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.0037\n",
      "Accuracy: 37816/47661 (79.34%)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "wrong_samples, wrong_preds, actual_preds = list(), list(), list()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x_minibatch, y_minibatch in test_dataloader:\n",
    "        x_minibatch = x_minibatch.to(device)  \n",
    "        y_minibatch = y_minibatch.to(device)      \n",
    "        y_test_pred = model(x_minibatch)\n",
    "        y_minibatch_indices = torch.argmax(y_minibatch, dim=1) \n",
    "        test_loss += loss_func(y_test_pred, y_minibatch_indices)  \n",
    "        pred = torch.argmax(y_test_pred, dim=1)\n",
    "        correct += pred.eq(y_minibatch_indices).sum().item()\n",
    "        \n",
    "        wrong_idx = pred.ne(y_minibatch_indices).nonzero()[:, 0].cpu().numpy().tolist()\n",
    "        for index in wrong_idx:\n",
    "            wrong_samples.append(x_minibatch[index].cpu())\n",
    "            wrong_preds.append(pred[index].cpu())\n",
    "            actual_preds.append(y_minibatch[index].cpu())\n",
    "            \n",
    "test_loss /= len(test_dataloader.dataset)\n",
    "print('Average Test Loss: {:.4f}'.format( test_loss ))\n",
    "print('Accuracy: {}/{} ({:.2f}%)'.format( correct, len(test_dataloader.dataset), 100 * correct / len(test_dataloader.dataset) ))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T07:00:52.529407100Z",
     "start_time": "2023-12-26T07:00:50.277677900Z"
    }
   },
   "id": "2aa2b10e39dd5c2b"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.0037\n",
      "Accuracy: 37816/47661 (79.34%)\n",
      "Precision: 0.7856\n",
      "Recall: 0.7934\n",
      "Confusion Matrix:\n",
      " [[26167  3211    13]\n",
      " [ 5058 11236   312]\n",
      " [  134  1117   413]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# ...\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "wrong_samples, wrong_preds, actual_preds = list(), list(), list()\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_minibatch, y_minibatch in test_dataloader:\n",
    "        x_minibatch = x_minibatch.to(device)  \n",
    "        y_minibatch = y_minibatch.to(device)      \n",
    "        y_test_pred = model(x_minibatch)\n",
    "        y_minibatch_indices = torch.argmax(y_minibatch, dim=1) \n",
    "        test_loss += loss_func(y_test_pred, y_minibatch_indices)  \n",
    "        pred = torch.argmax(y_test_pred, dim=1)\n",
    "        correct += pred.eq(y_minibatch_indices).sum().item()\n",
    "\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_targets.extend(y_minibatch_indices.cpu().numpy())\n",
    "\n",
    "        wrong_idx = pred.ne(y_minibatch_indices).nonzero()[:, 0].cpu().numpy().tolist()\n",
    "        for index in wrong_idx:\n",
    "            wrong_samples.append(x_minibatch[index].cpu())\n",
    "            wrong_preds.append(pred[index].cpu())\n",
    "            actual_preds.append(y_minibatch[index].cpu())\n",
    "\n",
    "test_loss /= len(test_dataloader.dataset)\n",
    "\n",
    "# Calculate precision, recall, and confusion matrix\n",
    "precision = precision_score(all_targets, all_preds, average='weighted')\n",
    "recall = recall_score(all_targets, all_preds, average='weighted')\n",
    "conf_matrix = confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "print('Average Test Loss: {:.4f}'.format(test_loss))\n",
    "print('Accuracy: {}/{} ({:.2f}%)'.format(correct, len(test_dataloader.dataset), 100 * correct / len(test_dataloader.dataset)))\n",
    "print('Precision: {:.4f}'.format(precision))\n",
    "print('Recall: {:.4f}'.format(recall))\n",
    "print('Confusion Matrix:\\n', conf_matrix)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T07:02:28.809319100Z",
     "start_time": "2023-12-26T07:02:26.433500400Z"
    }
   },
   "id": "23e470be12046aee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c1ebb457634e999"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
